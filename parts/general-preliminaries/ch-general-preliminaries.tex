\chapter{Prelogomena}
\label{ch:general-preliminaries}

\begin{chapterpresentation}
	\begin{abstract}
		We introduce the basic definitions and notations used throughout this thesis.
		Rather than reading it linearly, we recommand to skim it
		to get an idea of what it contains, and to only go back to this chapter
		only when needed, using the numerous internal hyperlinks.
	\end{abstract}
		
	\par\bigskip\bigskip
	\chaptertoc
\end{chapterpresentation}

\paragraph*{Notations.}
We try to use notations that syntactically reflect their type:
for instance, given a set $X$, we use Roman lowercases ($x,y,z,\dotsc$)
to denote elements of $X$, Roman uppercase for its subsets ($A, B, C, \dotsc$),
and cursive letters ($\+X, \dotsc$) for sets of subsets of $X$.
Functions are denoted by $f, g, h$, etc. and relations by
uppercase cursive letters ($\+R, \+S, \dotsc$).

Machines (Turing machines, automata, etc.) are also denoted
with uppercase cursive letters ($\+T$, $\+A$, $\dotsc$).
On the other hand, Greek letters are used to either denote queries ($\gamma, \delta, \dotsc$)
or formulas ($\phi, \chi, \psi, \dotsc$). When possible, we try to
use the letter to recall the semantics of the object: for instance in
\Cref{ch:semantic-tree-width-CRPQ}, $\gamma$ will be used to denote a base query,
$\alpha$ for one of its "\textbf{a}pproximation@approximation",
$\rho$ for a "\textbf{r}efinements@refinement" and
$\chi$ for an "e\textbf{x}pansion@expansion".
We reserve boldface letters for `complex objects' ("eg"
a "relational structure" $\?A$ or a monad $\?S$), and Blackboard bold
for canonical objects ("eg" the natural numbers $\N$).

We will use $\mathbb{A}, \mathbb{B}, \dotsc$ to denote
alphabets in \Cref{part:databases} and $\Sigma, \Gamma, \dotsc$
to denote them in \Cref{part:automatic}.
\footnote{``Pobody's Nerfect''...}
Lastly, decision problems are typesetted in small caps
("eg" "finite regular colourability"), 
complexity classes and categories in sans-serif ("coNP", "ExpSpace", $\Set[]$,
$\Pos[]$).


\section{Set and Functions}

We denote by $\N$, $\Np$ and $\Z$ the sets of natural numbers---that naturally contains zero--, the
of strictly positive natural numbers, and of integers, respectively.
For any $n\in\Np$, $\ZnZ{k}$ denotes the set of integers modulo $k$,
and for any $i,j \in \Z$, $\intro*\intInt{i,j}$ is the set of integers from $i$ to $j$,
bounds included.

The powerset---"ie" the set of all subsets---of set $X$
is denoted by $\intro*\pset{X}$, and $\intro*\psetp{X}$ is defined analogously
except that subsets are required to be non-empty.

While a function $f$ from set $X$ to set $Y$ is denoted by $f\colon X \to Y$,
we reserve $\intro*\pto$ and $\intro*\surj$ for partial functions and surjections, respectively.
The restriction of function $f$ to a subset $A$ of its domain is denoted by
$\intro*\restr{f}{A}$, and the identity function $x \mapsto x$ over set $X$
is denoted by $\intro*\id[X]$.
Given a function $f\colon X \to Y$ and a subset $A \subseteq X$,
we denote by $f[A]$ the direct image of $A$ by $f$.%
\footnote{In the literature, $f[A]$ is often abusively denoted by $f(A)$, although
this gives rise to an ambiguity between function application and direct images,
when there exists an element $A \in X$ "st" $A \subseteq X$: this happens for instance
when dealing with von Neumann's ordinals.}
Similarly, given a subset $B \subseteq Y$, $f^{-1}[B]$ denotes
the inverse image of $B$ by $f$, and when $B$ is a singleton $\{b\}$,
we will write $f^{-1}[b]$ instead.%

A binary relation $\+R$ over sets $X$ and $Y$---"ie" a subset $\+R \subseteq X \times Y$---
is said to be "functional@@rel" when for every $x$, there exists at most one $y$
"st" $\tup{x,y} \in \+R$.
When moreover $X = Y$, we say that it is:
\begin{itemize}
	\itemAP ""reflexive@@rel"" when $\tup{x,x} \in \+R$ for all $x \in X$;
	\itemAP ""symmetric@@rel"" when $\tup{x,y} \in \+R$ "iff" $\tup{y,x} \in \+R$
		for all $x,y \in X$;
	\itemAP transitive when $\tup{x,y} \in \+R$ and $\tup{y,z} \in \+R$
		imply $\tup{x,z} \in \+R$
		for all $x,y,z \in X$.
\end{itemize}
An equivalence relation over $X$ is any binary relation satisfying the three previous axioms.
Given an equivalence class $\sim$ over a set $X$ and an element $x \in X$,
we denote by $\intro*\equivclass[\sim]{x}$ the equivalence class of $x$ under $\sim$.

\section{Relational Structures}

\subsection{Basic Notions on Structures}

"Relational structures" generalize the concept of "graphs@@dir"
by allowing to have (1) multiple kinds of relations and
(2) relations of higher arity. This data is made explicit in
the "signature"---also called \emph{vocabulary}.
We start by defining a \AP""purely relational signature"", which consists
in a set of elements, called ""predicates"",%
\footnote{We do \emph{not} assume this set to be finite.}
together with for each
of these elements a strictly positive natural number, called \emph{arity}.
We denote by $\+R_{(k)} \in \sigma$ the fact that "predicate" $\+R$, of arity
$k$, is part of "signature" $\sigma$.
Then, a ""relational signature"", or ""signature"" for short, consists of a "purely relational 
signature" together with a set of constant symbols.%
\footnote{Usually the notion of "signature" also allows for function symbols beyond
the degenerate case of constants. However all the "signatures" considered in the thesis
will be "relational@@signature", justifying the abuse of terminology.}

Then, given a "signature" $\sigma$, a ""$\sigma$-structure"" $\?A$
consists of:
\begin{itemize}
	\item a set $A$, called \emph{domain},
	\item for each "predicate" $\+R_{(k)} \in \sigma$, a $k$-ary relation
		$\+R(\?A) \subseteq A^k$, and
	\item for each constant $c \in \sigma$, an element $c(\?A) \in A$.
\end{itemize}
We call $\+R_{(k)}$ (resp. $c(\?A)$) the \AP""interpretation@@predicate""
of "predicate" $\+R_{(k)}$ (resp. constant $c$) in $\?A$.
By analogy with graphs, elements of the domain are sometimes referred to as
\emph{vertices}.

The \AP""graph signature"" is a "purely relational signature"
consisting of a single binary predicate, either written $\+E$ in prefix notation
or $\atom{}$ in infix notation.
Then, the "$\sigma$-structures" over "this signature@graph signature"
exactly consists of \AP""directed graphs"".

An element of $\+R_{(k)}(\?A)$ is called an \AP""$\+R$-tuple""
of "structure" $\?A$. We also use the terminology \emph{edge} in place
of tuple for binary predicates.
An \reintro{hyperedge} of $\?A$ will designate any of its $\+R$-tuples,
indifferently of the "predicate" $\+R$.

A "$\sigma$-structure" $\?A$ is said to be \AP""finite@@struct"" when its
both its domain and its set of "hyperedges" are finite.
In particular, note that this last condition amounts to asking
that (1) for every "predicate" $\+R_{(k)} \in \sigma$, the relation $\+R_{(k)}(\?A)$ is finite,
and (2) there exists only finitely many "predicates" $\+R_{(k)} \in \sigma$
"st" $\+R_{(k)}(\?A)$ is non-empty.

A "substructure" of a "$\sigma$-structure" $\?A$ is another
"$\sigma$-structure" $\?A'$ "st":
\begin{itemize}
	\item the domain $A'$ of $\?A'$ is a subset of $A$,
	\item each ""interpretation@@predicate"" of a "predicate" in $\?A'$ 
		is a subset of its "interpretation@@predicate" in $\?A$, and
	\item every constant of $\?A$ belongs to $A'$, and the interpretation
		of the constants in both structures coincide. 
\end{itemize}
A "proper substructure" is a "substructure" for which
at least one of the inclusions in the first two points above
is strict: in other words, such a "substructure" should
miss at least one element, or one "hyperedge".

Given a subset $X$ of the domain $A$ of a "$\sigma$-structure" $\?A$,
the \emph{substructure of $\?A$ induced by $X$} is:
\begin{itemize}
	\item undefined if not all constants of $\?A$ belong to $X$,
	\item otherwise, it is obtained from $\?A$ by restricting
		its domain to $X$, and by intersection its $k$-ary relations
		with $X^k$.
\end{itemize}

The roles played by constants and "predicates" are obviously not symmetric.
For this reason we will often rather deal with "pointed structures".
Formally, given a "purely relational signature" $\sigma$,
a "pointed $\sigma$-structures" consists of a "$\sigma$-structure"
together with a \emph{tuple} of elements of its domain.
Note that "pointed $\sigma$-structures" with tuples of size $k\in \N$ are in natural
bijection with the set of "$\sigma'$-structures", where $\sigma'$
is obtained from $\sigma$ by adding a set of $k$ constants.

\subsection{Constructions on Structures}

The \AP""disjoint union"" of two "structures" over a
"purely relational signature" 
is obtained by taking the disjoint union of their domain and of
their "predicate interpretations".

We now let $\sigma$ to be any "signature".
Given two "$\sigma$-structures" $\?A$ and $\?B$, their
""Cartesian product"" \AP$\?A \intro*\prodstruct \?B$
is defined by taking the Cartesian product of their domain, of
their "predicate interpretations" and of their interpretations of constants. 
Their ""block product"" has the same domain and constants,
but now the "interpretation@@predicate" of "predicate" $\+R_{(k)}$
in the "block product" consists of all tuples
\[\tup{\tup{a_1,b_1}, \dotsc, \tup{a_k,b_k}}\] 
"st" either $\tup{a_1, \dotsc, a_k} \in \+R(\?A)
\land b_1 = \dotsc = b_k$ or 
$a_1 = \dotsc = a_k
\land \tup{b_1, \dotsc, b_k} \in \+R(\?B)$.

The $k$-fold iteration of $\?A$ is denoted by
$\intro*\iterstruct{\?A}{k}$ and is defined as
\[
	\underbrace{\?A \times \dotsc \times \?A}_{k \text{ times}}.
\]
\todo{example fig}

\subsection{Adjacencies}

Given a "$\sigma$-structure" $\?A$ and $a \in A$, we define the \AP""adjacency""%
\footnote{We do not use the terminology \emph{neighbourhood} since it usually refers
to a set of elements, namely the set of elements occurring in the "adjacency".}
of $a$ in $\?A$ to be the tuple of sets%
\AP\phantomintro{\adjacency}
\begin{align*}
	\reintro*\adjacency{a}{\?A}{\+R}{i} & \defeq
	% \Big\langle
		\big\{
			\langle a_1, \dotsc, a_{i-1}, a_{i+1}, \dotsc, a_k \rangle \in A^{k-1}
			\\ & \hphantom{\defeq \big\{ }\mid
			\langle a_1, \dotsc, a_{i-1}, a, a_{i+1}, \dotsc, a_k \rangle \in \+R(\?A)
		\big\},
		% \;\big\vert\;
		% \+R_{(k)} \in \sigma \text{ and } i \in \intInt{1,k}
	% \Big\rangle.
\end{align*}
when $\+R$ ranges over "predicate" of arity $k$ of $\sigma$ and $i \in \intInt{1,k}$. 
For "graphs@@dir", the "adjacency" of a vertex corresponds to its set of predecessors and
its set of successors.

\subsection{Undirected Paths}

An \AP""undirected path"" in a "$\sigma$-structure" $\?A$ consists of a sequence
\[\big\langle a_0,\, \bar h_0,\, a_1,\, \dotsc,\, \bar h_{n-1},\, a_n\big\rangle, \text{ with } n \in \N,\]
where $a_i \in A$ and each $\bar h_i$ is a "hyperedge" of $\?A$ "st" both
$a_i$ and $a_{i+1}$ occur in $\bar h_i$. When such an "undirected path" exists, we say that
there is an "undirected path" between $a_0$ and $a_n$, or equivalently
that $a_0$ and $a_n$ are \AP""connected"".%
\sidenote{Note that this defines an equivalence relation.}
A \AP"connected component" of $\?A$ consists of an equivalence class under this relation.

An ""undirected graph"" consists of a domain, together with
a set of (unordered) pairs of elements of the domain.
The ""incidence graph"" $\intro*\IncidenceGraph{\?A}$ of a "$\sigma$-structure",
for some "signature" $\sigma$, is the following "undirected graph":
\begin{itemize}
	\item its domain is the disjoint union of $A$
		and the "hyperedges" of $\?A$;
	\item there is an edge between two vertices "iff" one of them
		is a vertex $a$ of $\?A$, and the other is an hyperedge
		$\bar h$ of $\?A$, with the property that $a \in \bar h$.
\end{itemize}

The \AP""distance@@struct"" between two vertices of a "$\sigma$-structure"
is defined as half of their distance in the "incidence graph".%
\footnote{By construction the "incidence graph" is bipartite and hence
the distance between two vertices of the "structure" is even.}
The \AP""diameter"" of a "structure" is the maximum over $u$
of the minimum over $v$ of the "distance@@struct" between vertices $u$ and $v$.

The ball centred at vertex $a\in A$ and of radium $m\in\N$ of
a "$\sigma$-structure" $\?A$ is the "substructure" of $\?A$ induced by
all vertices at distance at most $m$.
A "structure" is said to be \AP""locally finite@@structure""
when every ball of finite radius is "finite@@struct".

A \AP""simple path"" in a "$\sigma$-structure" is a
simple path in its "incidence graph"---in other words, 
such a path should alternate between vertices and hyperedges,
and visit each of them at most once.

\subsection{Strings and Graphs}

The ""signature of binary strings"" has a binary "predicate" $\preceq$
as well as two unary predicates $0$ and $1$.
A binary string $b_0 \cdots b_{n-1}$ of length $n$
can be seen as a "structure" over the "signature of binary strings"
by taking $\intInt{0,n-1}$ as its domain, "interpreting@@predicate"
$\preceq$ naturally, and interpreting $0$ (resp. $1$) as the set of
of $i \in \intInt{0,n-1}$ "st" $b_i = 0$ (resp. $b_i = 1$).

A \AP""directed cycle"" in a "graph@@dir" consists
of a non-empty directed path from a vertex to itself.
A ""directed acyclic graph"", or \reintro{DAG} for short,
is any "graph@@dir" "st" that contains no "directed cycle".

A ""directed tree"" is a non-empty "graph@@dir" "st" there exists 
a vertex $r$ with the property that for every vertex $v$,
there exists exactly one directed path from $r$ to $v$.
\todo{figures}

The ""chromatic number"" of a "graph@@dir" is the least cardinal $k$
"st" it is "$k$-colourable". We say that a "graph@@dir"
is \AP""finitely colourable"" when its "chromatic number" is finite.


\subsection{Homomorphisms}

A \AP""homomorphism"" from a "$\sigma$-structure" $\?A$ to
to a "$\sigma$-structure" $\?B$ consists of a function $f$ from $A$ to $B$,
"st" for every $\+R_{(k)} \in \sigma$, for every $\tup{a_1,\dotsc,a_k} \in \+R(\?A)$,
we have $\tup{f(a_1), \dotsc, f(a_k)} \in \+R(\?B)$. Moreover, for every
constant $c \in \sigma$, we must have $f(c(\?A)) = c(\?B)$.

An \AP""embedding"" is an injective "homomorphism",
whereas a \AP""strong onto homomorphism"" is a "homomorphism" that is both
surjective on the domain and on the "hyperedges". 

An \AP""isomorphism"" from $\?A$ to $\?B$ is a "homomorphism" $f\colon \?A \to \?B$
"st" there exists another homomorphism $g\colon \?B \to \?A$ with the property
that $g \circ f = \id[A]$ and $f \circ g = \id[B]$. Equivalently,
it is "strong onto homomorphism" that is also an "embedding".
Two structures are \AP""isomorphic"" if there is an "isomorphism" between them,
and an ""automorphism"" is an "isomorphism" from a "structure" to itself.

Given "structures" $\?A_1, \dotsc, \?A_k$ sharing the same "signature",
the $i$-th projection from the Cartesian product $\?A_1 \prodstruct \dotsc \prodstruct \?A_k$
to $\?A_i$, defined by $\tup{a_1,\dotsc,a_k} \mapsto a_i$ ($i \in \intInt{1,k}$),
is a "homomorphism", and is denoted by \AP$\intro*\projHom{i}$.

Given a "$\sigma$-structure" $\?A$, a \AP""congruence@@struct"" on $\?A$
is an equivalence class $\sim$ of $A$ "st" for every
$\+R_{(k)} \in \sigma$, for every $\tup{a_1,\dotsc,a_k} \in \+R(\?A)$,
for any tuple $\tup{a'_1,\dotsc,a'_k} \in A^k$ "st" $a_i \sim a'_i$ for each $i\in \intInt{1,k}$,
then $\tup{a'_1,\dotsc,a'_k} \in \+R(\?A)$.
The \AP""quotient structure"" defined by a "congruence@@struct" $\sim$
on a "structure" $\?A$ has the equivalence classes of $\sim$ as its domain,
and natural "interpretation@@predicates" of the "predicates" and constants.

Given a "homomorphism" $f\colon \?A \to \?B$,
the \AP""congruence induced"" by $f$, and denoted by $\intro*\ker{f}$
is defined by $a \ker{f} a'$ "iff" $f(a) = f(a')$ for all $a, a' \in A$.
It is routine to check that it is indeed a "congruence@@struct" on $\?A$.

We will often implicitly use Noether's first isomorphism theorem:
the "substructure" of $\?B$ "induced@@substructure" by the image $f[A]$
of $A$ is "isomorphic" to the "quotient@@struct" of $\?A$ by $\ker{f}$.

\subsection{Cores}

Two "$\sigma$-structures" $\?A$ and $\?B$ are ""homomorphically equivalent""
if $\?A \homto \?B$ and $\?B \homto \?A$.

A retraction of $\?A$ is a "substructure" $\?A'$ of $\?A$ together with
a "homomorphism" from $\?A$ to $\?A'$ with the property that any vertex of $A'$
is sent on itself.
\begin{proposition}
	Any "finite $\sigma$-structure" $\?A$ admits a unique minimal retraction---by minimal
	we mean minimal in the number of vertices, and uniqueness is considered up to "isomorphism".
\end{proposition}

\begin{figure}
	\centering
	\begin{tikzpicture}
		\node[vertex, draw=c1, fill=c1, fill opacity=.4] at (0,1) (a) {};
		\node[vertex, draw=c0, fill=c0, fill opacity=.4] at (1.414,1) (b) {};
		\node[vertex, draw=c2, fill=c2, fill opacity=.4] at (2.828,1) (c) {};
		\node[vertex, draw=c1, fill=c1, fill opacity=.4] at (4.242,1) (d) {};
		\node[vertex, draw=c2, fill=c2, fill opacity=.4] at (0.707,0) (e) {};
		\node[vertex, draw=c1, fill=c1, fill opacity=.4] at (2.121,0) (f) {};
		\node[vertex, draw=c3, fill=c3, fill opacity=.4] at (3.536,0) (g) {};
		\node[vertex, draw=c0, fill=c0, fill opacity=.4] at (4.950,0) (h) {};

		\draw[edge] (a) to (b);
		\draw[edge] (b) to (e);
		\draw[edge] (f) to (b);
		\draw[edge] (b) to (c);
		\draw[edge] (f) to (c);
		\draw[edge] (g) to (f);
		\draw[edge] (c) to (g);
		\draw[edge] (d) to (c);
		\draw[edge] (g) to (d);
		\draw[edge] (d) to (h);

		\begin{scope}[xshift=5.5cm]
			\node[vertex, draw=c0, fill=c0, fill opacity=.4] at (1.414,1) (b2) {};
			\node[vertex, draw=c2, fill=c2, fill opacity=.4] at (2.828,1) (c2) {};
			\node[vertex, draw=c1, fill=c1, fill opacity=.4] at (2.121,0) (f2) {};
			\node[vertex, draw=c3, fill=c3, fill opacity=.4] at (3.536,0) (g2) {};

			\draw[edge] (f2) to (b2);
			\draw[edge] (b2) to (c2);
			\draw[edge] (f2) to (c2);
			\draw[edge] (g2) to (f2);
			\draw[edge] (c2) to (g2);
		\end{scope}
	\end{tikzpicture}
	\caption{
		\AP\label{fig:prelim-core}
		On the left-hand side a "graph@@dir", and its "core" on the right.
		The colours are not part of the "structure", but
		are used to describe the retraction of the original
		structure onto its "core".
		(Replica of \Cref{fig:intro-core}.)
	}
\end{figure}
\begin{proof}
	The existence is trivial.
	For the uniqueness, consider two retractions $f_1\colon \?A \homto \?B_1$
	and $f_2\colon \?A \homto \?B_2$. We want to prove that $\?B_1$ and $\?B_2$ are
	"isomorphic".

	Since $\?B_1$ is a "substructure" of $\?A$, consider
	$\restr{f_2}{B_1}\colon \?B_1 \homto \?B_2$. By minimality of $\?B_2$, this "homomorphism"
	must be surjective.
	By symmetry, $\restr{f_1}{B_2}\colon \?B_2 \homto \?B_1$ is also a surjective "homomorphism".
	By composition, we obtain surjective "homomorphism" from $\?B_1$ to itself and from $\?B_2$ to itself. By finiteness, these surjective "homomorphisms" must actually be "automorphisms".
	Hence, it follows that $\restr{f_2}{B_1}$ and $\restr{f_1}{B_2}$ are "isomorphisms",
	and hence $\?B_1$ is "isomorphic" to $\?B_2$.
\end{proof}

This unique minimal retraction of $\?A$ is called \AP""core"" of $\?A$ and
is denoted by \AP$\intro*\core{\?B}$.
By construction, the "core" of $\?A$ is a "substructure" of $\?A$ to which it is "homomorphically equivalent", see \Cref{fig:prelim-core}.
In general, a \reintro{core} is any "$\sigma$-structure" such that is the "core" of
some "structure"---or equivalently of itself.

\begin{proposition}
	\AP\label{prop:core-iff-hom-are-auto}
	A "finite $\sigma$-structure" $\?C$ is a "core" if, and only if, every
	homomorphism from $\?C$ to itself is an "automorphism".
\end{proposition}

\begin{proof}
	For the left-to-right implication,
	we let $f\colon \?C \to \?C$ be a "homomorphism".
	Then $f[\?C]$ must be "isomorphic" to $\?C$, otherwise we would obtain
	a strictly smaller retraction. Hence, $f$ is a "strong onto homomorphism"
	from $\?C$ to itself, and hence is an "automorphism".
	
	Conversely, assuming that any "homomorphism" from $\?C$ to itself is an "automorphism"
	we get in particular that any retraction must be an "automorphism", and
	hence that $\?C$ is "isomorphic" to $\core{\?C}$.
\end{proof}

\begin{proposition}
	Two "finite structures" are "homomorphically equivalent" if,
	and only if, their "core" are "isomorphic".
\end{proposition}

\begin{proof}
	The right-to-left implication is trivial.
	For the converse one, denote the two "structures" by $\?A_1$ and $\?A_2$,
	and suppose that $\?A_1$ is "homomorphically equivalent" to $\?A_2$.
	Using the "homomorphical equivalence" of $\?A_1$ and $\?A_2$,
	we get retractions of $\?A_2$ onto $\core{\?A_1}$ and of $\?A_1$ onto $\core{\?A_2}$.
	It follows that we have surjective "homomorphisms" from $\core{\?A_1}$ to $\core{\?A_2}$
	and conversely. Hence, $\core{\?A_1}$ and $\core{\?A_2}$ are "isomorphic".
\end{proof}

\begin{proposition}
	\AP\label{prop:adjacency-core}
	Given a "$\sigma$-structure" $\?B$, if $\?B$ is a "core", then
	two elements $b_1$ and $b_2$ of $\?B$ have the same "adjacency" "iff" $b_1 = b_2$.
\end{proposition}

\begin{proof}
	The right-to-left implication is trivial.
	For the converse one, consider the "homomorphism" from $\?B$ to itself
	which maps $b_2$ to $b_1$, and all elements of $B \smallsetminus \{b_2\}$
	to themselves. Since we assumed that $b_1$ and $b_2$ have the same "adjacency",
	this is indeed a "homomorphism", which is clearly not bijective, and
	$\?B$ is not a "core".
\end{proof}

\section{Logic Related Notions}

\subsection{First-Order Logic and Beyond}

""queries@@sem""

We assume that we are given a countable infinite set of variables.


\begin{itemize}
	\itemAP ""first-order logic""
	\itemAP ""first-order formula"", ""first-order sentence""
	\itemAP ""models"", $\intro*\FOmodels$ and $\intro*\semFO{-}{-}$
	\itemAP ""quantifier alternation""
	\itemAP ""first-order definable""
	\itemAP ""existential formula"", ""existential-positive formula"",
		""positive quantifier-free formula""
	\itemAP ""monadic second-order logic""
\end{itemize}

\subsection{Automata Theory}

\begin{itemize}
	\itemAP $^*$ (knowledgify)
	\itemAP ""regular language"", $\intro*\2$
	\itemAP $\intro*\transition{a}$
\end{itemize}

\subsection{Monoids}

\begin{itemize}
	\itemAP ""finite monoid"", ""monoid morphism""
	\itemAP ""syntactic monoids"", ""syntactic morphism""
	\itemAP ""pseudovariety of finite monoids"", ""pseudovariety of regular languages""
	\itemAP ""membership@@problang""
\end{itemize}

\section{Complexity}

\begin{itemize}
	\itemAP ""Turing machine""
	\itemAP ""configuration@@TM""
	\itemAP ""initial configuration""
	\itemAP ""reachable configuration""
\end{itemize}

\begin{itemize}
	\itemAP ""Connectivity in Finite Graphs""
	\itemAP ""Reachability in Finite Graphs""
	\itemAP ""computationally equivalent""
	\itemAP ""data complexity""
	\item \cite{Schmitz2016ComplexityHierarchies} for "Tower" $\intro*\tower$
\end{itemize}